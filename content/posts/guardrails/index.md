---
title: "How I Built Toxic Content Classifiers for LLM Guardrails"
summary: "In this post I compare two classifiers that I built for toxic content classification: LLM-based classifier and Feed Forward Neural Network classifier. I found surprising results."
date: 2024-10-07
series: ["Guardrails"]
weight: 1
aliases: ["/guardrails"]
tags: ["RAG", "LLMs", "Langchain", "OpenAI", "LlamaIndex", "ChromaDB"]
author: ["Dr Julija"]
cover:
    image: "/posts/guardrails/images/toxic-cover.png"  # image path/url
    alt: "Hello" # alt text
    caption: "Basic Rag Pipeline | ðŸ“” DrJulija's Notebook | Follow my [Medium Blog](https://medium.com/p/938e4f6e03d1)" # display caption under cover
    relative: false # when using page bundles set this to true
---

Hello